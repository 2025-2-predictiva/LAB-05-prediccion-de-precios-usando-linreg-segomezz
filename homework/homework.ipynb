{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción del dataset\n",
    "\n",
    "\n",
    " En este dataset se desea pronosticar el precio de vhiculos usados. El dataset\n",
    " original contiene las siguientes columnas:\n",
    "\n",
    " - Car_Name: Nombre del vehiculo.\n",
    " - Year: Año de fabricación.\n",
    " - Selling_Price: Precio de venta.\n",
    " - Present_Price: Precio actual.\n",
    " - Driven_Kms: Kilometraje recorrido.\n",
    " - Fuel_type: Tipo de combustible.\n",
    " - Selling_Type: Tipo de vendedor.\n",
    " - Transmission: Tipo de transmisión.\n",
    " - Owner: Número de propietarios.\n",
    "\n",
    " El dataset ya se encuentra dividido en conjuntos de entrenamiento y prueba\n",
    " en la carpeta \"files/input/\".\n",
    "\n",
    " Los pasos que debe seguir para la construcción de un modelo de\n",
    " pronostico están descritos a continuación.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Paso 1.\n",
    " Preprocese los datos.\n",
    " - Cree la columna 'Age' a partir de la columna 'Year'.\n",
    "   Asuma que el año actual es 2021.\n",
    " - Elimine las columnas 'Year' y 'Car_Name'.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 2.\n",
    " Divida los datasets en x_train, y_train, x_test, y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "import pickle\n",
    "import gzip\n",
    "import json\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error,make_scorer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif,f_regression, mutual_info_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def carga_y_limpieza(train_path, test_path):\n",
    "    # Leer los datasets descomprimidos\n",
    "    train_dataset = pd.read_csv(train_path)\n",
    "    test_dataset = pd.read_csv(test_path)\n",
    "    print(train_dataset.shape)\n",
    "    print(test_dataset.shape)\n",
    "\n",
    "    # -- Elimine los registros con informacion no disponible.\n",
    "    train_dataset.dropna(inplace=True)\n",
    "    test_dataset.dropna(inplace=True)\n",
    "\n",
    "    train_dataset[\"Age\"] = 2021 - train_dataset[\"Year\"]\n",
    "    train_dataset = train_dataset.drop([\"Car_Name\", \"Year\"], axis=1)\n",
    "    x_train = train_dataset.drop(columns=[\"Present_Price\"])\n",
    "    y_train = train_dataset[\"Present_Price\"]\n",
    "\n",
    "\n",
    "    test_dataset[\"Age\"] = 2021 - test_dataset[\"Year\"]\n",
    "    test_dataset = test_dataset.drop([\"Car_Name\", \"Year\"], axis=1)\n",
    "    x_test = test_dataset.drop(columns=[\"Present_Price\"])\n",
    "    y_test = test_dataset[\"Present_Price\"]\n",
    "    categorical_columns=[\"Fuel_Type\",\"Selling_type\",\"Transmission\"]\n",
    "    numerical_columns=[\"Selling_Price\",\"Driven_kms\",\"Owner\",\"Age\"]\n",
    "\n",
    "    print(x_train.shape)\n",
    "    print(x_test.shape)\n",
    "\n",
    "    return x_train, y_train, x_test, y_test, categorical_columns,numerical_columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 3.\n",
    "Cree un pipeline para el modelo de clasificación. Este pipeline debe\n",
    "contener las siguientes capas:\n",
    "- Transforma las variables categoricas usando el método\n",
    "  one-hot-encoding.\n",
    "- Escala las variables numéricas al intervalo [0, 1].\n",
    "- Selecciona las K mejores entradas.\n",
    "- Ajusta un modelo de regresion lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipeline(estimator, categorical_columns=None, numeric_columns=None):\n",
    "    # --- Preprocesamiento ---\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_columns),\n",
    "            ('num', MinMaxScaler(), numeric_columns)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # --- Pipeline completo ---\n",
    "    pipeline = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor),                      \n",
    "        (\"selectkbest\", SelectKBest()),  # selección de variables\n",
    "        (\"estimator\", estimator)                  \n",
    "    ])\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 4.\n",
    "Optimice los hiperparametros del pipeline usando validación cruzada.\n",
    "Use 10 splits para la validación cruzada. Use el error medio absoluto\n",
    "para medir el desempeño modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_grid_search(estimator, param_grid, cv=10):\n",
    "\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=estimator,\n",
    "        param_grid=param_grid,\n",
    "        scoring=make_scorer(mean_absolute_error, greater_is_better=False),\n",
    "        cv=cv,\n",
    "        n_jobs=-1,\n",
    "        refit=True,\n",
    "    )\n",
    "\n",
    "    return grid_search "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 5.\n",
    " Guarde el modelo (comprimido con gzip) como \"files/models/model.pkl.gz\".\n",
    " Recuerde que es posible guardar el modelo comprimido usanzo la libreria gzip.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_estimator(estimator):\n",
    "\n",
    "    os.makedirs(\"../files/models\", exist_ok=True)\n",
    "    with gzip.open(\"../files/models/model.pkl.gz\", \"wb\") as f:\n",
    "        pickle.dump(estimator, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 6.\n",
    " Calcule las metricas r2, error cuadratico medio, y error absoluto medio\n",
    " para los conjuntos de entrenamiento y prueba. Guardelas en el archivo\n",
    " files/output/metrics.json. Cada fila del archivo es un diccionario con\n",
    " las metricas de un modelo. Este diccionario tiene un campo para indicar\n",
    " si es el conjunto de entrenamiento o prueba. Por ejemplo:\n",
    "\n",
    " {'type': 'metrics', 'dataset': 'train', 'r2': 0.8, 'mse': 0.7, 'mad': 0.9}\n",
    " {'type': 'metrics', 'dataset': 'test', 'r2': 0.7, 'mse': 0.6, 'mad': 0.8}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guardar_metricas(best_model,y_train, y_train_pred, y_test, y_test_pred, output_path):\n",
    "    # Calcular métricas para el conjunto de entrenamiento\n",
    "    train_metrics = {\n",
    "        'type': 'metrics',\n",
    "        'dataset': 'train',\n",
    "        'r2': r2_score(y_train, y_train_pred),\n",
    "        'mse': mean_squared_error(y_train, y_train_pred),\n",
    "        'mad': mean_absolute_error(y_train, y_train_pred)\n",
    "    }\n",
    "\n",
    "    # Calcular métricas para el conjunto de prueba\n",
    "    test_metrics = {\n",
    "        'type': 'metrics',\n",
    "        'dataset': 'test',\n",
    "        'r2': r2_score(y_test, y_test_pred),\n",
    "        'mse': mean_squared_error(y_test, y_test_pred),\n",
    "        'mad': mean_absolute_error(y_test, y_test_pred)\n",
    "    }\n",
    "\n",
    "    # Guardar las métricas en un archivo JSON\n",
    "    with open(output_path, 'w') as f:\n",
    "        f.write(json.dumps(train_metrics) + '\\n')\n",
    "        f.write(json.dumps(test_metrics) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejecución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(211, 9)\n",
      "(90, 9)\n",
      "(211, 7)\n",
      "(90, 7)\n"
     ]
    }
   ],
   "source": [
    "def regresion_lineal():\n",
    "    train_path=\"../files/input/train_data.csv\"\n",
    "    test_path=\"../files/input/test_data.csv\"\n",
    "\n",
    "    # --- Paso 1 y 2: Carga y limpieza ---\n",
    "    x_train, y_train, x_test, y_test, categorical_columns, numeric_columns = carga_y_limpieza(train_path, test_path)\n",
    "\n",
    "        # --- Paso 3: Pipeline ---\n",
    "    pipeline = build_pipeline(\n",
    "        estimator=LinearRegression(),\n",
    "        categorical_columns=categorical_columns,\n",
    "        numeric_columns=numeric_columns,\n",
    "    )\n",
    "\n",
    "    param_grid = {\n",
    "    'selectkbest__k': [i for i in range(1, 10)],  # Probar con todas las características\n",
    "    'selectkbest__score_func': [f_regression, mutual_info_regression], \n",
    "}\n",
    "    \n",
    "    grid_search = make_grid_search(\n",
    "        estimator=pipeline,\n",
    "        param_grid=param_grid,\n",
    "        cv=10,\n",
    "    )\n",
    "\n",
    "    grid_search.fit(x_train,y_train)\n",
    "\n",
    "    ##Guardar estimador\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    save_estimator(grid_search)\n",
    "    y_train_pred = best_model.predict(x_train)\n",
    "    y_test_pred = best_model.predict(x_test)\n",
    "    \n",
    "\n",
    "    ##Guardar metricas\n",
    "\n",
    "    output_path = \"../files/output/metrics.json\"\n",
    "    guardar_metricas(best_model, y_train, y_train_pred, y_test, y_test_pred, output_path)\n",
    "\n",
    "regresion_lineal()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
